{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astronomy 8824 - Problem Set 5 \n",
    "The goal of this problem set is to gain familiarity with Fisher Matrix Forecasts.\n",
    "\n",
    "This problem set was developed by David Weinberg, with some modifications by Paul Martini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import matrix\n",
    "from numpy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from astropy.io import ascii\n",
    "\n",
    "# matplotlib settings \n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)   # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    '''\n",
    "    Calculate a gaussian with mean mu and dispersion sig at input points x\n",
    "    '''\n",
    "    return np.exp( -0.5 * np.power( (x - mu)/sig, 2.)) / (np.sqrt(2*np.pi)*sig)\n",
    "\n",
    "def PlotTwoDist(xy1, label1, xy2=None, label2=None, dims=None, addgauss=False, gxsig=False, gysig=False, xy2hist=True, axes=[\"X\", \"Y\"], connect=20): \n",
    "    '''\n",
    "    xy1, xy2: (x,y) points for the two distributions\n",
    "    label1, label2: labels for the two distributions\n",
    "    dims: [xc, yc, dx, dy] where xc,yc are the plot center and dx, dy are the half sizes of the plot\n",
    "    addgauss: (bool) True to overplot Gaussian on each histogram\n",
    "    xy2hist: (bool) Plot histograms for second distribution\n",
    "    axes: [\"X\", \"Y\"] Labels for axes\n",
    "    connect: (default 20) Initial set of points to connect with a solid line\n",
    "    gxsig, gysig: (float) sigma values for the two histograms\n",
    "    '''\n",
    "    \n",
    "    if dims is not None:\n",
    "        xc = dims[0]\n",
    "        yc = dims[1]\n",
    "        dx = dims[2]\n",
    "        dy = dims[3]\n",
    "        xbins = np.arange(xc - dx, xc + dx, 0.05*dx)\n",
    "        ybins = np.arange(yc - dy, yc + dy, 0.05*dy)\n",
    "    else: \n",
    "        xbins = []\n",
    "        ybins = []\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    gs = GridSpec(4,4)\n",
    "    ax_scatter = fig.add_subplot(gs[1:4, 0:3])\n",
    "    ax_xhist = fig.add_subplot(gs[0,0:3])\n",
    "    ax_yhist = fig.add_subplot(gs[1:4,3])\n",
    "    ax_scatter.scatter(xy1[0], xy1[1], color='k', s=1, label=label1)\n",
    "    ax_xhist.hist(xy1[0], bins=xbins, histtype='step', color='k', density=True)\n",
    "    ax_yhist.hist(xy1[1], bins=ybins, histtype='step', color='k', density=True, orientation='horizontal')\n",
    "\n",
    "    if xy2 is not None: \n",
    "        ax_scatter.scatter(xy2[0], xy2[1], color='r', s=1, label=label2)\n",
    "        ax_scatter.plot(xy2[0][:connect], xy2[1][:connect], color='r', ls='-')\n",
    "        if xy2hist: \n",
    "            ax_xhist.hist(xy2[0], bins=xbins, histtype='step', color='r', density=True)\n",
    "            ax_xhist.hist(xy2[0], bins=xbins, histtype='step', color='r', density=True)\n",
    "            ax_yhist.hist(xy2[1], bins=xbins, histtype='step', color='r', density=True, orientation='horizontal')\n",
    "\n",
    "    if addgauss and gxsig and gysig: \n",
    "        if dims is not None:\n",
    "            ggxx = np.linspace(xc - dx, xc + dx, 100)\n",
    "            ggx = gaussian(ggxx, xc, gxsig)\n",
    "            ax_xhist.plot(ggxx, ggx)\n",
    "            ggyy = np.linspace(yc - dy, yc + dy, 100)\n",
    "            ggy = gaussian(ggyy, yc, gysig)\n",
    "            ax_yhist.plot(ggy, ggyy)            \n",
    "        else: \n",
    "            gg = np.linspace(-1*size, size, 100)\n",
    "            ggx = gaussian(gg, 0., gxsig)\n",
    "            ggy = gaussian(gg, 0., gysig)\n",
    "            ax_xhist.plot(gg, ggx)\n",
    "            ax_yhist.plot(ggy, gg)\n",
    "    \n",
    "    plt.setp(ax_xhist.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_xhist.get_yticklabels(), visible=False)\n",
    "    plt.setp(ax_yhist.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_yhist.get_yticklabels(), visible=False)\n",
    "    ax_scatter.set_xlabel(axes[0], fontsize=16)\n",
    "    ax_scatter.set_ylabel(axes[1], fontsize=16)\n",
    "    if dims is not None: \n",
    "        ax_scatter.set_xlim(xc - dx, xc + dx)\n",
    "        ax_scatter.set_ylim(yc - dy, yc + dy)\n",
    "        ax_xhist.set_xlim(xc - dx, xc + dx)\n",
    "        ax_yhist.set_ylim(yc - dy, yc + dy)\n",
    "\n",
    "\n",
    "    ax_xhist.set_ylabel(\"N\", fontsize=16)\n",
    "    ax_yhist.set_xlabel(\"N\", fontsize=16)\n",
    "    ax_scatter.legend(frameon=False, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(x,cinv,prefac):\n",
    "    \"\"\"\n",
    "    Return multivariate Gaussian probability\n",
    "    x = vector of data values  (matrix)\n",
    "    cinv = inverse covariance matrix\n",
    "    prefac = prefactor for properly normalized Gaussian (float),\n",
    "             taken as input so that it isn't computed every call\n",
    "             should be [(2\\pi)^{M/2} \\sqrt{det(C)}]^{-1}\n",
    "    \"\"\"\n",
    "    arg=float(x*cinv*x.T)\n",
    "    return (prefac*np.exp(-arg/2.))\n",
    "\n",
    "def rundmc(data, initvals, stepvals, nchain, nthin=1, cov=None, intype=1):\n",
    "    '''\n",
    "    Read in data from a file (intype=1) or array (intype=2) and use MCMC to sample the \n",
    "    distribution of parameter values\n",
    "    initvals, stepvals : arrays of initial values and step sizes. Each array is 3 elements. To only sample two \n",
    "      parameters, set last element of stepvals to be zero.\n",
    "    nchain : number of steps\n",
    "    nthin : thin the chain by this amount\n",
    "    intype = 1 (datafile) or 2 (data)\n",
    "    cov = input covariance matrix, will be diagonal if cov=None\n",
    "    '''\n",
    "    \n",
    "    if intype == 1: \n",
    "        x, y, errors = np.loadtxt(data, unpack=True)\n",
    "    elif intype ==  2:\n",
    "        x, y, errors = data[0], data[1], data[2]\n",
    "    else:\n",
    "        print(\"Error with {} format\".format(data))\n",
    "    t1init = initvals[0]\n",
    "    t2init = initvals[1]\n",
    "    t3init = initvals[2]\n",
    "    step1 = stepvals[0]\n",
    "    step2 = stepvals[1]\n",
    "    step3 = stepvals[2]\n",
    "    \n",
    "    if cov is None:\n",
    "        cov = np.diag(errors)\n",
    "        \n",
    "    cinv = np.linalg.inv(cov)\n",
    "    prefac=1./(2*np.pi*np.sqrt(np.linalg.det(cov)))\n",
    "\n",
    "    t1 = t1init\n",
    "    t2 = t2init\n",
    "    t3 = t3init\n",
    "    deltay = y - (t1 + t2*x + t3*x*x)\n",
    "    dym = matrix(deltay)\n",
    "    p1 = prob(dym,cinv,prefac)        # probability at starting point\n",
    "\n",
    "    chain=np.zeros((nchain,4))    # store (theta1,theta2,theta3,p) as elements of chain\n",
    "    chain[0][0] = t1\n",
    "    chain[0][1] = t2\n",
    "    chain[0][2] = t3\n",
    "    chain[0][3] = p1\n",
    "\n",
    "    ichain = 1\n",
    "    naccept = 0\n",
    "    while (ichain < nchain):\n",
    "        t1trial = t1+step1*np.random.normal()\n",
    "        t2trial = t2+step2*np.random.normal()\n",
    "        t3trial = t3 + step3*np.random.normal()\n",
    "        deltay = y - (t1trial + t2trial*x + t3trial*x*x)\n",
    "        dym = matrix(deltay)\n",
    "        p2 = prob(dym,cinv,prefac)            # compute probability\n",
    "        if ((p2>p1 or p1==0) or np.random.random()<p2/p1):    # accept step?\n",
    "            chain[ichain][0]=t1trial\n",
    "            chain[ichain][1]=t2trial\n",
    "            chain[ichain][2]=t3trial\n",
    "            chain[ichain][3]=p2\n",
    "            t1=t1trial\n",
    "            t2=t2trial\n",
    "            t3=t3trial\n",
    "            p1=p2\n",
    "            naccept+=1\n",
    "        else:\n",
    "            chain[ichain][0]=t1\n",
    "            chain[ichain][1]=t2\n",
    "            chain[ichain][2]=t3\n",
    "            chain[ichain][3]=p2\n",
    "        ichain+=1\n",
    "\n",
    "    xaccept=float(naccept)/float(ichain)\n",
    "    print('%.4f of trials accepted' % (xaccept))\n",
    "    return chain[::nthin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaTex macros hidden here --\n",
    "\n",
    "$\\newcommand{\\xhat}{\\hat{x}}$\n",
    "$\\newcommand{\\xmin}{x_{min}}$\n",
    "$\\newcommand{\\xmax}{x_{max}}$\n",
    "$\\newcommand{\\cinvkl}{C_{kl}^{-1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fisher Matrix Forecast, linear fit\n",
    "\n",
    "Suppose you have 20 (x,y) data points generated from a linear relation y = $\\theta_1 + \\theta_2 x$ with x uniformly distributed in the range $5 < x < 20$ and independent Gaussian errors on y with standard deviation $\\sigma = 1$. \n",
    "\n",
    "#### a. What is the Fisher matrix?\n",
    "\n",
    "$$ \n",
    "F_{ij} = \\left< \\frac{\\partial^2 ln L}{\\partial\\theta_i \\partial\\theta_j} \\right> ?\n",
    "$$\n",
    "Express your answer in terms of $\\sigma$ and $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) What is the inverse of the Fisher matrix? \n",
    "\n",
    "Express your answer in terms of the $\\sigma$, $x$, and the minimum and maximum value $x_{min}$ and $x_{max}$. _Hint:_ The expectation value is $<x> = (x_{max} + x_{min})/2.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) If both the intercept $\\theta_1$ and the slope $\\theta_2$ are to be estimated by fitting the data, what are the expected errors on $\\theta_1$ and $\\theta_2$?\n",
    "\n",
    "Use your results from b) to compute numerical values for $\\Delta \\theta_1$ and $\\Delta \\theta_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) If the slope $\\theta_2$ is known and you only need to solve for $\\theta_1$, what is the expected error? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) How does the expected slope error change if N = 6 instead of N = 20? How does the expect slope error change if xmax = 15 instead of xmax = 20?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MCMC parameters of a linear fit\n",
    "\n",
    "The repository includes the data files:\n",
    "- line.n20.s12.dat\n",
    "- line.n20.s17.dat\n",
    "- line.n20.s0.dat\n",
    "- line.n6.s0.dat\n",
    "  \n",
    "These files have (x, y, σ) data points, with σ = 1 in all cases and x evenly spaced in the range 5 – 20. They were generated by the David's program linedata.py (also included), which you should look at to check that you understand what it is doing. For the two files labeled ‘s0.dat’ the points have been forced to lie exactly on the prescribed line. \n",
    "\n",
    "This notebook includes the function rundmc(), which reads a data file in this format and generates an MCMC for the intercept and slope (θ1, θ2) of a linear fit. You can either use this code or refer to it and write your own. Note that the probability is proportional to exp(-$\\chi^2$/2), and you do not have to compute the constant of proportionality because you only need ratios of probabilities for your MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['line.n20.s12.dat', 'line.n20.s17.dat', 'line.n20.s0.dat', 'line.n6.s0.dat']\n",
    "\n",
    "data1 = ascii.read(filenames[0])\n",
    "data2 = ascii.read(filenames[1])\n",
    "data3 = ascii.read(filenames[2])\n",
    "data4 = ascii.read(filenames[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)\tFor the first two files, compute the best-fit slope and intercept using the formulas we have discussed in class (and are given in Numerical Recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Generate an MCMC chain for the first 3 files (with N=20). Plot (theta1, theta2) for each and compare the marginal distributions of (theta1, theta2) to the Gaussian distributions with the erorrs you predicted from Part 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Plot instead the distribution of ($\\theta_1 + 12.5 \\theta_2, \\theta_2$).  Comment on the result. Relate your interpretation of this result to the Fisher matrix (think particularly about the moments that enter there). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Repeat b) for line.n6.s0.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A Third Parameter\n",
    "\n",
    "Suppose that with the same (N = 20) data you allow a third parameter with a quadratic term, $y = \\theta_1 + \\theta_2 x + \\theta_3 x^2$. For the fiducial model being assumed for the forecast, you adopt $\\theta_3 = 0$, but you allow it to be free in the fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) What is the Fisher Matrix in this case? (You can do the matrix inversion numerically.)  What are the forecast errors on $\\theta_1, \\theta_2, \\theta_3$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Use rundmc() or your own code to create a chain for this 3-parameter model. Apply it to the files line.n20.s0.dat and line.n6.s0.dat and plot the results, with particular attention to $\\theta_3$ vs. $\\theta_2$. Compare the errors from MCMC to your Fisher matrix forecast. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Correlated Errors\n",
    "\n",
    "The code linepluscov() generates a distribution of points with correlated errors. Run the code for 20 points in the range x = 5 – 20 with a slope $\\theta_2 = 0.5$ and intercept $\\theta_1 = 2$ for the random number seeds 12 and 17 used previously for the diagonal case. For this problem we are changing the slope from $\\theta_2 = 2$ to $\\theta_2 = 0.5$ while keeping $\\sigma = 1$. This shrinks the vertical scale relative to the error bar, making the effect of correlations easier to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linepluscov(xmin, xmax, npoints, a, b, seed):\n",
    "\n",
    "    '''\n",
    "    Generate points on a line with errors drawn from a multivariate Gaussian with various \n",
    "    covariance matrices\n",
    "    \n",
    "    Parameters:\n",
    "       xmin,xmax = range of x values\n",
    "       npoints = number of points, evenly distributed in xmin,xmax\n",
    "       a, b = slope and intercept of line\n",
    "       seed = random number seed\n",
    "       \n",
    "    Written by DHW, modified for notebook by PM\n",
    "    '''\n",
    "    \n",
    "    sigma=1.0\n",
    "    np.random.seed(seed)\n",
    "    output = {}\n",
    "\n",
    "    x=np.linspace(xmin,xmax,npoints)\n",
    "    y=a*x+b\n",
    "\n",
    "    errors=sigma*np.ones(npoints)\n",
    "    mu=np.zeros(npoints)\n",
    "    cov=np.diag(errors)\n",
    "    delta=np.random.multivariate_normal(mu,cov)\n",
    "    y1=y+delta    \n",
    "    output['A'] = np.transpose([x,y1,errors])\n",
    "\n",
    "    offd=0.2\n",
    "    b=offd*np.ones(npoints-1)\n",
    "    cov1=cov+np.diag(b,1)+np.diag(b,-1)\n",
    "    delta=np.random.multivariate_normal(mu,cov1)\n",
    "    y1=y+delta\n",
    "    output['B'] = np.transpose([x,y1,errors])\n",
    "\n",
    "    offd=-0.2\n",
    "    b=offd*np.ones(npoints-1)\n",
    "    cov1=cov+np.diag(b,1)+np.diag(b,-1)\n",
    "    delta=np.random.multivariate_normal(mu,cov1)\n",
    "    y1=y+delta\n",
    "    output['C'] = np.transpose([x,y1,errors])\n",
    "\n",
    "    offd=0.4\n",
    "    b=offd*np.ones(npoints-1)\n",
    "    cov1=cov+np.diag(b,1)+np.diag(b,-1)\n",
    "    delta=np.random.multivariate_normal(mu,cov1)\n",
    "    y1=y+delta\n",
    "    output['D'] = np.transpose([x,y1,errors])\n",
    "\n",
    "    offd=0.4\n",
    "    cov1=offd*np.ones((npoints,npoints))+np.diag(errors-offd)\n",
    "    delta=np.random.multivariate_normal(mu,cov1)\n",
    "    y1=y+delta\n",
    "    output['E'] = np.transpose([x,y1,errors])\n",
    "\n",
    "    return output\n",
    "\n",
    "# Generate two realizations\n",
    "output12 = linepluscov(5, 20, 20, 0.5, 2, 12)\n",
    "output17 = linepluscov(5, 20, 20, 0.5, 2, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)\tWhat covariance matrices are being used for the five sets of data points (A, B, C, D, E) that the code produces? (Look at the code to figure out what it is doing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Plot the two realizations of N = 20 points for each of the five cases, attaching error bars, and including the y = 0.5 x + 2 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (OPTIONAL) Parameter errors with correlated data errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Compute the predicted errors on $\\theta_1$ and $\\theta_2$ for each case from Part 4. You’ll now need to compute the Fisher matrix using the expression with the full covariance matrix (Stats Notes 4, page 5) and invert it numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1, sigma2\n"
     ]
    }
   ],
   "source": [
    "#### Answer\n",
    "\n",
    "sigma = 1.0\n",
    "N = 20\n",
    "xmin = 5\n",
    "xmax = 20\n",
    "a = 0.5 \n",
    "b = 2.\n",
    "x = np.linspace(xmin, xmax, N)\n",
    "y = a*x + b\n",
    "errors = sigma*np.ones(N)\n",
    "mu = np.zeros(N)\n",
    "\n",
    "# Case A: \n",
    "covA = np.diag(errors)\n",
    "\n",
    "# Case B: \n",
    "offd = 0.2\n",
    "b = offd*np.ones(N-1)\n",
    "covB = covA + np.diag(b, 1) + np.diag(b, -1)\n",
    "\n",
    "# Case C: \n",
    "offd = -0.2\n",
    "b = offd*np.ones(N-1)\n",
    "covC = covA + np.diag(b, 1) + np.diag(b, -1)\n",
    "\n",
    "# Case D: \n",
    "offd = 0.4\n",
    "b = offd*np.ones(N-1)\n",
    "covD = covA + np.diag(b, 1) + np.diag(b, -1)\n",
    "\n",
    "# Case E: \n",
    "offd = 0.4\n",
    "covE = offd*np.ones((N, N)) + np.diag(errors-offd)\n",
    "\n",
    "def get_fisher(cov, x, label):\n",
    "    '''\n",
    "    your code here\n",
    "    '''\n",
    "    fish = np.diag( (2, 2) ) # replace this\n",
    "    fishinv = linalg.inv(fish)\n",
    "    return fish, fishinv\n",
    "\n",
    "print(\"sigma1, sigma2\")\n",
    "fishA, fishAinv = get_fisher(covA, x, \"Case A\")\n",
    "fishB, fishBinv = get_fisher(covB, x, \"Case B\")\n",
    "fishC, fishCinv = get_fisher(covC, x, \"Case C\")\n",
    "fishD, fishDinv = get_fisher(covD, x, \"Case D\")\n",
    "fishE, fishEinv = get_fisher(covE, x, \"Case E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) How do the correlated errors affect the expected parameter errors? Does the behavior make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) For D and E, check the Fisher matrix against the MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
